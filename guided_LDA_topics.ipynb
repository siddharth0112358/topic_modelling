{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "https://www.kaggle.com/nvpsani/topic-modelling-using-guided-lda"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "https://medium.com/analytics-vidhya/how-i-tackled-a-real-world-problem-with-guidedlda-55ee803a6f0d"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting lda\n",
      "  Downloading lda-2.0.0-cp38-cp38-macosx_10_9_x86_64.whl (344 kB)\n",
      "\u001b[K     |████████████████████████████████| 344 kB 3.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.13.0 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from lda) (1.19.5)\n",
      "Collecting pbr<4,>=0.6\n",
      "  Downloading pbr-3.1.1-py2.py3-none-any.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 11.0 MB/s \n",
      "\u001b[?25hInstalling collected packages: pbr, lda\n",
      "  Attempting uninstall: pbr\n",
      "    Found existing installation: pbr 5.5.1\n",
      "    Uninstalling pbr-5.5.1:\n",
      "      Successfully uninstalled pbr-5.5.1\n",
      "Successfully installed lda-2.0.0 pbr-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lda"
   ]
  },
  {
   "source": [
    "# GuidedLDA utilities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, unicode_literals  # noqa\n",
    "\n",
    "import logging\n",
    "import numbers\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "PY2 = sys.version_info[0] == 2\n",
    "if PY2:\n",
    "    import itertools\n",
    "    zip = itertools.izip\n",
    "\n",
    "\n",
    "# logger = logging.getLogger('guidedlda')\n",
    "## edit 1.9.2020\n",
    "logger = logging.getLogger('lda')\n",
    "\n",
    "\n",
    "def check_random_state(seed):\n",
    "    if seed is None:\n",
    "        # i.e., use existing RandomState\n",
    "        return np.random.mtrand._rand\n",
    "    if isinstance(seed, (numbers.Integral, np.integer)):\n",
    "        return np.random.RandomState(seed)\n",
    "    if isinstance(seed, np.random.RandomState):\n",
    "        return seed\n",
    "    raise ValueError(\"{} cannot be used as a random seed.\".format(seed))\n",
    "\n",
    "\n",
    "def matrix_to_lists(doc_word):\n",
    "    \"\"\"Convert a (sparse) matrix of counts into arrays of word and doc indices\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_word : array or sparse matrix (D, V)\n",
    "        document-term matrix of counts\n",
    "    Returns\n",
    "    -------\n",
    "    (WS, DS) : tuple of two arrays\n",
    "        WS[k] contains the kth word in the corpus\n",
    "        DS[k] contains the document index for the kth word\n",
    "    \"\"\"\n",
    "    if np.count_nonzero(doc_word.sum(axis=1)) != doc_word.shape[0]:\n",
    "        logger.warning(\"all zero row in document-term matrix found\")\n",
    "    if np.count_nonzero(doc_word.sum(axis=0)) != doc_word.shape[1]:\n",
    "        logger.warning(\"all zero column in document-term matrix found\")\n",
    "    sparse = True\n",
    "    try:\n",
    "        # if doc_word is a scipy sparse matrix\n",
    "        doc_word = doc_word.copy().tolil()\n",
    "    except AttributeError:\n",
    "        sparse = False\n",
    "\n",
    "    if sparse and not np.issubdtype(doc_word.dtype, int):\n",
    "        raise ValueError(\"expected sparse matrix with integer values, found float values\")\n",
    "\n",
    "    ii, jj = np.nonzero(doc_word)\n",
    "    if sparse:\n",
    "        ss = tuple(doc_word[i, j] for i, j in zip(ii, jj))\n",
    "    else:\n",
    "        ss = doc_word[ii, jj]\n",
    "\n",
    "    n_tokens = int(doc_word.sum())\n",
    "    DS = np.repeat(ii, ss).astype(np.intc)\n",
    "    WS = np.empty(n_tokens, dtype=np.intc)\n",
    "    startidx = 0\n",
    "    for i, cnt in enumerate(ss):\n",
    "        cnt = int(cnt)\n",
    "        WS[startidx:startidx + cnt] = jj[i]\n",
    "        startidx += cnt\n",
    "    return WS, DS\n",
    "\n",
    "\n",
    "def lists_to_matrix(WS, DS):\n",
    "    \"\"\"Convert array of word (or topic) and document indices to doc-term array\n",
    "    Parameters\n",
    "    -----------\n",
    "    (WS, DS) : tuple of two arrays\n",
    "        WS[k] contains the kth word in the corpus\n",
    "        DS[k] contains the document index for the kth word\n",
    "    Returns\n",
    "    -------\n",
    "    doc_word : array (D, V)\n",
    "        document-term array of counts\n",
    "    \"\"\"\n",
    "    D = max(DS) + 1\n",
    "    V = max(WS) + 1\n",
    "    doc_word = np.empty((D, V), dtype=np.intc)\n",
    "    for d in range(D):\n",
    "        for v in range(V):\n",
    "            doc_word[d, v] = np.count_nonzero(WS[DS == d] == v)\n",
    "    return doc_word\n",
    "\n",
    "\n",
    "def dtm2ldac(dtm, offset=0):\n",
    "    \"\"\"Convert a document-term matrix into an LDA-C formatted file\n",
    "    Parameters\n",
    "    ----------\n",
    "    dtm : array of shape N,V\n",
    "    Returns\n",
    "    -------\n",
    "    doclines : iterable of LDA-C lines suitable for writing to file\n",
    "    Notes\n",
    "    -----\n",
    "    If a format similar to SVMLight is desired, `offset` of 1 may be used.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dtm = dtm.tocsr()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    assert np.issubdtype(dtm.dtype, int)\n",
    "    n_rows = dtm.shape[0]\n",
    "    for i, row in enumerate(dtm):\n",
    "        try:\n",
    "            row = row.toarray().squeeze()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        unique_terms = np.count_nonzero(row)\n",
    "        if unique_terms == 0:\n",
    "            raise ValueError(\"dtm row {} has all zero entries.\".format(i))\n",
    "        term_cnt_pairs = [(i + offset, cnt) for i, cnt in enumerate(row) if cnt > 0]\n",
    "        docline = str(unique_terms) + ' '\n",
    "        docline += ' '.join([\"{}:{}\".format(i, cnt) for i, cnt in term_cnt_pairs])\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            logger.info(\"dtm2ldac: on row {} of {}\".format(i + 1, n_rows))\n",
    "        yield docline\n",
    "\n",
    "\n",
    "def ldac2dtm(stream, offset=0):\n",
    "    \"\"\"Convert an LDA-C formatted file to a document-term array\n",
    "    Parameters\n",
    "    ----------\n",
    "    stream: file object\n",
    "        File yielding unicode strings in LDA-C format.\n",
    "    Returns\n",
    "    -------\n",
    "    dtm : array of shape N,V\n",
    "    Notes\n",
    "    -----\n",
    "    If a format similar to SVMLight is the source, an `offset` of 1 may be used.\n",
    "    \"\"\"\n",
    "    doclines = stream\n",
    "\n",
    "    # We need to figure out the dimensions of the dtm.\n",
    "    N = 0\n",
    "    V = -1\n",
    "    data = []\n",
    "    for l in doclines:\n",
    "        l = l.strip()\n",
    "        # skip empty lines\n",
    "        if not l:\n",
    "            continue\n",
    "        unique_terms = int(l.split(' ')[0])\n",
    "        term_cnt_pairs = [s.split(':') for s in l.split(' ')[1:]]\n",
    "        for v, _ in term_cnt_pairs:\n",
    "            # check that format is indeed LDA-C with the appropriate offset\n",
    "            if int(v) == 0 and offset == 1:\n",
    "                raise ValueError(\"Indexes in LDA-C are offset 1\")\n",
    "        term_cnt_pairs = tuple((int(v) - offset, int(cnt)) for v, cnt in term_cnt_pairs)\n",
    "        np.testing.assert_equal(unique_terms, len(term_cnt_pairs))\n",
    "        V = max(V, *[v for v, cnt in term_cnt_pairs])\n",
    "        data.append(term_cnt_pairs)\n",
    "        N += 1\n",
    "    V = V + 1\n",
    "    dtm = np.zeros((N, V), dtype=np.intc)\n",
    "    for i, doc in enumerate(data):\n",
    "        for v, cnt in doc:\n",
    "            np.testing.assert_equal(dtm[i, v], 0)\n",
    "            dtm[i, v] = cnt\n",
    "    return dtm"
   ]
  },
  {
   "source": [
    "# Guided LDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\"\"\"Latent Dirichlet allocation using collapsed Gibbs sampling\"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, unicode_literals  # noqa\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lda._lda\n",
    "# import lda.utils\n",
    "## edit 1.9.2020\n",
    "\n",
    "import random\n",
    "\n",
    "logger = logging.getLogger('lda')\n",
    "\n",
    "PY2 = sys.version_info[0] == 2\n",
    "if PY2:\n",
    "    range = xrange\n",
    "\n",
    "\n",
    "class GuidedLDA:\n",
    "    \"\"\"Guided Latent Dirichlet allocation using collapsed Gibbs sampling\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_topics : int\n",
    "        Number of topics\n",
    "    n_iter : int, default 2000\n",
    "        Number of sampling iterations\n",
    "    alpha : float, default 0.1\n",
    "        Dirichlet parameter for distribution over topics\n",
    "    eta : float, default 0.01\n",
    "        Dirichlet parameter for distribution over words\n",
    "    random_state : int or RandomState, optional\n",
    "        The generator used for the initial topics.\n",
    "    Attributes\n",
    "    ----------\n",
    "    `components_` : array, shape = [n_topics, n_features]\n",
    "        Point estimate of the topic-word distributions (Phi in literature)\n",
    "    `topic_word_` :\n",
    "        Alias for `components_`\n",
    "    `word_topic_` : array, shape = [n_features, n_topics]\n",
    "        Point estimate of the word-topic distributions\n",
    "    `nzw_` : array, shape = [n_topics, n_features]\n",
    "        Matrix of counts recording topic-word assignments in final iteration.\n",
    "    `ndz_` : array, shape = [n_samples, n_topics]\n",
    "        Matrix of counts recording document-topic assignments in final iteration.\n",
    "    `doc_topic_` : array, shape = [n_samples, n_features]\n",
    "        Point estimate of the document-topic distributions (Theta in literature)\n",
    "    `nz_` : array, shape = [n_topics]\n",
    "        Array of topic assignment counts in final iteration.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy\n",
    "    >>> X = numpy.array([[1,1], [2, 1], [3, 1], [4, 1], [5, 8], [6, 1]])\n",
    "    >>> import lda\n",
    "    >>> model = lda.LDA(n_topics=2, random_state=0, n_iter=100)\n",
    "    >>> model.fit(X) #doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
    "    LDA(alpha=...\n",
    "    >>> model.components_\n",
    "    array([[ 0.85714286,  0.14285714],\n",
    "           [ 0.45      ,  0.55      ]])\n",
    "    >>> model.loglikelihood() #doctest: +ELLIPSIS\n",
    "    -40.395...\n",
    "    References\n",
    "    ----------\n",
    "    Blei, David M., Andrew Y. Ng, and Michael I. Jordan. \"Latent Dirichlet\n",
    "    Allocation.\" Journal of Machine Learning Research 3 (2003): 993–1022.\n",
    "    Griffiths, Thomas L., and Mark Steyvers. \"Finding Scientific Topics.\"\n",
    "    Proceedings of the National Academy of Sciences 101 (2004): 5228–5235.\n",
    "    doi:10.1073/pnas.0307752101.\n",
    "    Wallach, Hanna, David Mimno, and Andrew McCallum. \"Rethinking LDA: Why\n",
    "    Priors Matter.\" In Advances in Neural Information Processing Systems 22,\n",
    "    edited by Y.  Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A.\n",
    "    Culotta, 1973–1981, 2009.\n",
    "    Buntine, Wray. \"Estimating Likelihoods for Topic Models.\" In Advances in\n",
    "    Machine Learning, First Asian Conference on Machine Learning (2009): 51–64.\n",
    "    doi:10.1007/978-3-642-05224-8_6.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_topics, n_iter=2000, alpha=0.01, eta=0.01, random_state=None,\n",
    "                 refresh=10):\n",
    "        self.n_topics = n_topics\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "        self.eta = eta\n",
    "        # if random_state is None, check_random_state(None) does nothing\n",
    "        # other than return the current numpy RandomState\n",
    "        self.random_state = random_state\n",
    "        self.refresh = refresh\n",
    "\n",
    "        if alpha <= 0 or eta <= 0:\n",
    "            raise ValueError(\"alpha and eta must be greater than zero\")\n",
    "\n",
    "        # random numbers that are reused\n",
    "        rng = lda.utils.check_random_state(random_state)\n",
    "        if random_state:\n",
    "            random.seed(random_state)\n",
    "        self._rands = rng.rand(1024**2 // 8)  # 1MiB of random variates\n",
    "\n",
    "        # configure console logging if not already configured\n",
    "        if len(logger.handlers) == 1 and isinstance(logger.handlers[0], logging.NullHandler):\n",
    "            logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    def fit(self, X, y=None, seed_topics={}, seed_confidence=0):\n",
    "        \"\"\"Fit the model with X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples in the number of samples\n",
    "            and n_features is the number of features. Sparse matrix allowed.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns the instance itself.\n",
    "        \"\"\"\n",
    "\n",
    "        self._fit(X, seed_topics=seed_topics, seed_confidence=seed_confidence)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None, seed_topics={}, seed_confidence=0):\n",
    "        \"\"\"Apply dimensionality reduction on X\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            New data, where n_samples in the number of samples\n",
    "            and n_features is the number of features. Sparse matrix allowed.\n",
    "        Returns\n",
    "        -------\n",
    "        doc_topic : array-like, shape (n_samples, n_topics)\n",
    "            Point estimate of the document-topic distributions\n",
    "        \"\"\"\n",
    "        if isinstance(X, np.ndarray):\n",
    "            # in case user passes a (non-sparse) array of shape (n_features,)\n",
    "            # turn it into an array of shape (1, n_features)\n",
    "            X = np.atleast_2d(X)\n",
    "        self._fit(X, seed_topics=seed_topics, seed_confidence=seed_confidence)\n",
    "        return self.doc_topic_\n",
    "\n",
    "    def transform(self, X, max_iter=20, tol=1e-16):\n",
    "        \"\"\"Transform the data X according to previously fitted model\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            New data, where n_samples in the number of samples\n",
    "            and n_features is the number of features.\n",
    "        max_iter : int, optional\n",
    "            Maximum number of iterations in iterated-pseudocount estimation.\n",
    "        tol: double, optional\n",
    "            Tolerance value used in stopping condition.\n",
    "        Returns\n",
    "        -------\n",
    "        doc_topic : array-like, shape (n_samples, n_topics)\n",
    "            Point estimate of the document-topic distributions\n",
    "        Note\n",
    "        ----\n",
    "        This uses the \"iterated pseudo-counts\" approach described\n",
    "        in Wallach et al. (2009) and discussed in Buntine (2009).\n",
    "        \"\"\"\n",
    "        if isinstance(X, np.ndarray):\n",
    "            # in case user passes a (non-sparse) array of shape (n_features,)\n",
    "            # turn it into an array of shape (1, n_features)\n",
    "            X = np.atleast_2d(X)\n",
    "        doc_topic = np.empty((X.shape[0], self.n_topics))\n",
    "        WS, DS = lda.utils.matrix_to_lists(X)\n",
    "        # TODO: this loop is parallelizable\n",
    "        for d in np.unique(DS):\n",
    "            doc_topic[d] = self._transform_single(WS[DS == d], max_iter, tol)\n",
    "        return doc_topic\n",
    "\n",
    "    def _transform_single(self, doc, max_iter, tol):\n",
    "        \"\"\"Transform a single document according to the previously fit model\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1D numpy array of integers\n",
    "            Each element represents a word in the document\n",
    "        max_iter : int\n",
    "            Maximum number of iterations in iterated-pseudocount estimation.\n",
    "        tol: double\n",
    "            Tolerance value used in stopping condition.\n",
    "        Returns\n",
    "        -------\n",
    "        doc_topic : 1D numpy array of length n_topics\n",
    "            Point estimate of the topic distributions for document\n",
    "        Note\n",
    "        ----\n",
    "        See Note in `transform` documentation.\n",
    "        \"\"\"\n",
    "        PZS = np.zeros((len(doc), self.n_topics))\n",
    "        for iteration in range(max_iter + 1): # +1 is for initialization\n",
    "            PZS_new = self.components_[:, doc].T\n",
    "            PZS_new *= (PZS.sum(axis=0) - PZS + self.alpha)\n",
    "            PZS_new /= PZS_new.sum(axis=1)[:, np.newaxis] # vector to single column matrix\n",
    "            delta_naive = np.abs(PZS_new - PZS).sum()\n",
    "            logger.debug('transform iter {}, delta {}'.format(iteration, delta_naive))\n",
    "            PZS = PZS_new\n",
    "            if delta_naive < tol:\n",
    "                break\n",
    "        theta_doc = PZS.sum(axis=0) / PZS.sum()\n",
    "        assert len(theta_doc) == self.n_topics\n",
    "        assert theta_doc.shape == (self.n_topics,)\n",
    "        return theta_doc\n",
    "\n",
    "    def _fit(self, X, seed_topics, seed_confidence):\n",
    "        \"\"\"Fit the model to the data X\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, shape (n_samples, n_features)\n",
    "            Training vector, where n_samples in the number of samples and\n",
    "            n_features is the number of features. Sparse matrix allowed.\n",
    "        \"\"\"\n",
    "        random_state = lda.utils.check_random_state(self.random_state)\n",
    "        rands = self._rands.copy()\n",
    "\n",
    "        self._initialize(X, seed_topics, seed_confidence)\n",
    "        for it in range(self.n_iter):\n",
    "            # FIXME: using numpy.roll with a random shift might be faster\n",
    "            random_state.shuffle(rands)\n",
    "            if it % self.refresh == 0:\n",
    "                ll = self.loglikelihood()\n",
    "                logger.info(\"<{}> log likelihood: {:.0f}\".format(it, ll))\n",
    "                # keep track of loglikelihoods for monitoring convergence\n",
    "                self.loglikelihoods_.append(ll)\n",
    "            self._sample_topics(rands)\n",
    "        ll = self.loglikelihood()\n",
    "        logger.info(\"<{}> log likelihood: {:.0f}\".format(self.n_iter - 1, ll))\n",
    "        # note: numpy /= is integer division\n",
    "        self.components_ = (self.nzw_ + self.eta).astype(float)\n",
    "        self.components_ /= np.sum(self.components_, axis=1)[:, np.newaxis]\n",
    "        self.topic_word_ = self.components_\n",
    "\n",
    "        self.word_topic_ = (self.nzw_ + self.eta).astype(float)\n",
    "        self.word_topic_ /= np.sum(self.word_topic_, axis=0)[np.newaxis, :]\n",
    "        self.word_topic_ = self.word_topic_.T\n",
    "        self.doc_topic_ = (self.ndz_ + self.alpha).astype(float)\n",
    "        self.doc_topic_ /= np.sum(self.doc_topic_, axis=1)[:, np.newaxis]\n",
    "\n",
    "        # delete attributes no longer needed after fitting to save memory and reduce clutter\n",
    "        del self.WS\n",
    "        del self.DS\n",
    "        del self.ZS\n",
    "        return self\n",
    "\n",
    "    def _initialize(self, X, seed_topics, seed_confidence):\n",
    "        \"\"\"Initialize the document topic distribution.\n",
    "        topic word distribution, etc.\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed_topics: type=dict, value={2:0, 256:0, 412:1, 113:1}\n",
    "        \"\"\"\n",
    "        D, W = X.shape\n",
    "        N = int(X.sum())\n",
    "        n_topics = self.n_topics\n",
    "        n_iter = self.n_iter\n",
    "        logger.info(\"n_documents: {}\".format(D))\n",
    "        logger.info(\"vocab_size: {}\".format(W))\n",
    "        logger.info(\"n_words: {}\".format(N))\n",
    "        logger.info(\"n_topics: {}\".format(n_topics))\n",
    "        logger.info(\"n_iter: {}\".format(n_iter))\n",
    "\n",
    "        self.beta = 0.1\n",
    "        self.nzw_ = nzw_ = np.zeros((n_topics, W), dtype=np.intc) # + self.beta\n",
    "        self.ndz_ = ndz_ = np.zeros((D, n_topics), dtype=np.intc) # + self.alpha\n",
    "        self.nz_ = nz_ = np.zeros(n_topics, dtype=np.intc)# + W * self.beta\n",
    "\n",
    "        self.WS, self.DS = WS, DS = lda.utils.matrix_to_lists(X)\n",
    "        self.ZS = ZS = np.empty_like(self.WS, dtype=np.intc)\n",
    "        np.testing.assert_equal(N, len(WS))\n",
    "\n",
    "        # seeded Initialization\n",
    "        count_testing = 0\n",
    "        for i in range(N):\n",
    "            w, d = WS[i], DS[i]\n",
    "            if w not in seed_topics:\n",
    "                continue\n",
    "            # check if seeded initialization\n",
    "            if w in seed_topics and random.random() < seed_confidence:\n",
    "                z_new = seed_topics[w]\n",
    "            else:\n",
    "                z_new = i % n_topics\n",
    "            ZS[i] = z_new\n",
    "            ndz_[d, z_new] += 1\n",
    "            nzw_[z_new, w] += 1\n",
    "            nz_[z_new] += 1\n",
    "\n",
    "        # Non seeded Initialization\n",
    "        for i in range(N):\n",
    "            w, d = WS[i], DS[i]\n",
    "            if w in seed_topics:\n",
    "                continue\n",
    "            z_new = i % n_topics\n",
    "            ZS[i] = z_new\n",
    "            ndz_[d, z_new] += 1\n",
    "            nzw_[z_new, w] += 1\n",
    "            nz_[z_new] += 1\n",
    "\n",
    "        self.loglikelihoods_ = []\n",
    "\n",
    "        self.nzw_ = nzw_.astype(np.intc)\n",
    "        self.ndz_ = ndz_.astype(np.intc)\n",
    "        self.nz_ = nz_.astype(np.intc)\n",
    "\n",
    "    def purge_extra_matrices(self):\n",
    "        \"\"\"Clears out word topic. document topic. and internal matrix.\n",
    "        Once this method is used. don't call fit_transform again.\n",
    "        Just use the model for predictions.\n",
    "        \"\"\"\n",
    "        del self.topic_word_\n",
    "        del self.word_topic_\n",
    "        del self.doc_topic_\n",
    "        del self.nzw_\n",
    "        del self.ndz_\n",
    "        del self.nz_\n",
    "\n",
    "    def loglikelihood(self):\n",
    "        \"\"\"Calculate complete log likelihood, log p(w,z)\n",
    "        Formula used is log p(w,z) = log p(w|z) + log p(z)\n",
    "        \"\"\"\n",
    "        nzw, ndz, nz = self.nzw_, self.ndz_, self.nz_\n",
    "        alpha = self.alpha\n",
    "        eta = self.eta\n",
    "        nd = np.sum(ndz, axis=1).astype(np.intc)\n",
    "        return lda._lda._loglikelihood(nzw, ndz, nz, nd, alpha, eta)\n",
    "\n",
    "    def _sample_topics(self, rands):\n",
    "        \"\"\"Samples all topic assignments. Called once per iteration.\"\"\"\n",
    "        n_topics, vocab_size = self.nzw_.shape\n",
    "        alpha = np.repeat(self.alpha, n_topics).astype(np.float64)\n",
    "        eta = np.repeat(self.eta, vocab_size).astype(np.float64)\n",
    "        lda._lda._sample_topics(self.WS, self.DS, self.ZS, self.nzw_, self.ndz_, self.nz_,\n",
    "                                            alpha, eta, rands)"
   ]
  },
  {
   "source": [
    "# LDA dataset preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "medical_df = pd.read_csv(\"/Users/sdeshpande/Desktop/bioinformatices/full_articlesLDA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                  paper_id  \\\n",
       "0           0  0001418189999fea7f7cbe3e82703d71c85a6fe5   \n",
       "1           1  000affa746a03f1fe4e3b3ef1a62fdfa9b9ac52a   \n",
       "2           2  000e754142ba65ef77c6fdffcbcbe824e141ea7b   \n",
       "3           3  000eec3f1e93c3792454ac59415c928ce3a6b4ad   \n",
       "4           4  001259ae6d9bfa9376894f61aa6b6c5f18be2177   \n",
       "\n",
       "                                               title  \\\n",
       "0  Absence of surface expression of feline infect...   \n",
       "1  Correlation between antimicrobial consumption ...   \n",
       "2  Laboratory-based surveillance of hospital-acqu...   \n",
       "3  Pneumonie virale sévère de l'immunocompétent V...   \n",
       "4  Microheterogeneity of S-glycoprotein of mouse ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Feline infectious peritonitis virus (FIPV) pos...   \n",
       "1  Objectives: This study was conducted to invest...   \n",
       "2  Of 7,772 laboratory-confirmed cases of respira...   \n",
       "3  Reçu et accepté le 7 février 2004 Les infectio...   \n",
       "4  IEF, isoelectric focusing; NC, nitrocellulose;...   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  Feline infectious peritonitis (FIP) is a fatal...   \n",
       "1  The incidence of health-care-associated infect...   \n",
       "2  The human respiratory viruses include adenovir...   \n",
       "3  Les pathologies infectieuses respiratoires son...   \n",
       "4  (Accepted 10 January 1992) is a neurotropic co...   \n",
       "\n",
       "                                           doi  \\\n",
       "0  http://doi.org/10.1016/j.vetmic.2006.11.026   \n",
       "1    http://doi.org/10.1016/j.jmii.2013.10.008   \n",
       "2    http://doi.org/10.1016/j.ajic.2017.01.009   \n",
       "3  http://doi.org/10.1016/j.reaurg.2004.02.009   \n",
       "4  http://doi.org/10.1016/0166-0934(92)90173-B   \n",
       "\n",
       "                                 title_abstract_body  \n",
       "0  Absence of surface expression of feline infect...  \n",
       "1  Correlation between antimicrobial consumption ...  \n",
       "2  Laboratory-based surveillance of hospital-acqu...  \n",
       "3  Pneumonie virale sévère de l'immunocompétent V...  \n",
       "4  Microheterogeneity of S-glycoprotein of mouse ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>paper_id</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>body_text</th>\n      <th>doi</th>\n      <th>title_abstract_body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0001418189999fea7f7cbe3e82703d71c85a6fe5</td>\n      <td>Absence of surface expression of feline infect...</td>\n      <td>Feline infectious peritonitis virus (FIPV) pos...</td>\n      <td>Feline infectious peritonitis (FIP) is a fatal...</td>\n      <td>http://doi.org/10.1016/j.vetmic.2006.11.026</td>\n      <td>Absence of surface expression of feline infect...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>000affa746a03f1fe4e3b3ef1a62fdfa9b9ac52a</td>\n      <td>Correlation between antimicrobial consumption ...</td>\n      <td>Objectives: This study was conducted to invest...</td>\n      <td>The incidence of health-care-associated infect...</td>\n      <td>http://doi.org/10.1016/j.jmii.2013.10.008</td>\n      <td>Correlation between antimicrobial consumption ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>000e754142ba65ef77c6fdffcbcbe824e141ea7b</td>\n      <td>Laboratory-based surveillance of hospital-acqu...</td>\n      <td>Of 7,772 laboratory-confirmed cases of respira...</td>\n      <td>The human respiratory viruses include adenovir...</td>\n      <td>http://doi.org/10.1016/j.ajic.2017.01.009</td>\n      <td>Laboratory-based surveillance of hospital-acqu...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>000eec3f1e93c3792454ac59415c928ce3a6b4ad</td>\n      <td>Pneumonie virale sévère de l'immunocompétent V...</td>\n      <td>Reçu et accepté le 7 février 2004 Les infectio...</td>\n      <td>Les pathologies infectieuses respiratoires son...</td>\n      <td>http://doi.org/10.1016/j.reaurg.2004.02.009</td>\n      <td>Pneumonie virale sévère de l'immunocompétent V...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>001259ae6d9bfa9376894f61aa6b6c5f18be2177</td>\n      <td>Microheterogeneity of S-glycoprotein of mouse ...</td>\n      <td>IEF, isoelectric focusing; NC, nitrocellulose;...</td>\n      <td>(Accepted 10 January 1992) is a neurotropic co...</td>\n      <td>http://doi.org/10.1016/0166-0934(92)90173-B</td>\n      <td>Microheterogeneity of S-glycoprotein of mouse ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "medical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            doi  \\\n",
       "0   http://doi.org/10.1016/j.vetmic.2006.11.026   \n",
       "1     http://doi.org/10.1016/j.jmii.2013.10.008   \n",
       "2     http://doi.org/10.1016/j.ajic.2017.01.009   \n",
       "3   http://doi.org/10.1016/j.reaurg.2004.02.009   \n",
       "4   http://doi.org/10.1016/0166-0934(92)90173-B   \n",
       "5       http://doi.org/10.3389/fimmu.2015.00527   \n",
       "6      http://doi.org/10.1101/2020.01.10.901801   \n",
       "7   http://doi.org/10.1016/0166-0934(94)00119-2   \n",
       "8  http://doi.org/10.1016/j.econmod.2016.02.017   \n",
       "9    http://doi.org/10.1016/j.cimid.2018.09.011   \n",
       "\n",
       "                                            abstract  \n",
       "0  Feline infectious peritonitis virus (FIPV) pos...  \n",
       "1  Objectives: This study was conducted to invest...  \n",
       "2  Of 7,772 laboratory-confirmed cases of respira...  \n",
       "3  Reçu et accepté le 7 février 2004 Les infectio...  \n",
       "4  IEF, isoelectric focusing; NC, nitrocellulose;...  \n",
       "5  Dendritic cells (DCs) are specialized antigen-...  \n",
       "6  word count: 194 22 Text word count: 5168 23 24...  \n",
       "7  The effects of centrifugation on the ability o...  \n",
       "8  We review the basic concepts of intervention a...  \n",
       "9  The present study evaluated the changes in sal...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doi</th>\n      <th>abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://doi.org/10.1016/j.vetmic.2006.11.026</td>\n      <td>Feline infectious peritonitis virus (FIPV) pos...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://doi.org/10.1016/j.jmii.2013.10.008</td>\n      <td>Objectives: This study was conducted to invest...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://doi.org/10.1016/j.ajic.2017.01.009</td>\n      <td>Of 7,772 laboratory-confirmed cases of respira...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://doi.org/10.1016/j.reaurg.2004.02.009</td>\n      <td>Reçu et accepté le 7 février 2004 Les infectio...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://doi.org/10.1016/0166-0934(92)90173-B</td>\n      <td>IEF, isoelectric focusing; NC, nitrocellulose;...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>http://doi.org/10.3389/fimmu.2015.00527</td>\n      <td>Dendritic cells (DCs) are specialized antigen-...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>http://doi.org/10.1101/2020.01.10.901801</td>\n      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>http://doi.org/10.1016/0166-0934(94)00119-2</td>\n      <td>The effects of centrifugation on the ability o...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>http://doi.org/10.1016/j.econmod.2016.02.017</td>\n      <td>We review the basic concepts of intervention a...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>http://doi.org/10.1016/j.cimid.2018.09.011</td>\n      <td>The present study evaluated the changes in sal...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "medical_df = medical_df[[\"doi\",\"abstract\"]]\n",
    "medical_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_df = medical_df[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           doi  \\\n",
       "0  http://doi.org/10.1016/j.vetmic.2006.11.026   \n",
       "1    http://doi.org/10.1016/j.jmii.2013.10.008   \n",
       "2    http://doi.org/10.1016/j.ajic.2017.01.009   \n",
       "3  http://doi.org/10.1016/j.reaurg.2004.02.009   \n",
       "4  http://doi.org/10.1016/0166-0934(92)90173-B   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Feline infectious peritonitis virus  FIPV  pos...   \n",
       "1  Objectives  This study was conducted to invest...   \n",
       "2  Of       laboratory confirmed cases of respira...   \n",
       "3  Re u et accept  le   f vrier      Les infectio...   \n",
       "4  IEF  isoelectric focusing  NC  nitrocellulose ...   \n",
       "\n",
       "                                      abstract_clean  \n",
       "0  feline infectious peritonitis virus fipv posit...  \n",
       "1  objectives study investigate correlation antib...  \n",
       "2  laboratory cases respiratory viral infection p...  \n",
       "3  et accept le vrier les infections virales resp...  \n",
       "4  ief isoelectric nc tbs tris saline ph tbs milk...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doi</th>\n      <th>abstract</th>\n      <th>abstract_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://doi.org/10.1016/j.vetmic.2006.11.026</td>\n      <td>Feline infectious peritonitis virus  FIPV  pos...</td>\n      <td>feline infectious peritonitis virus fipv posit...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://doi.org/10.1016/j.jmii.2013.10.008</td>\n      <td>Objectives  This study was conducted to invest...</td>\n      <td>objectives study investigate correlation antib...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://doi.org/10.1016/j.ajic.2017.01.009</td>\n      <td>Of       laboratory confirmed cases of respira...</td>\n      <td>laboratory cases respiratory viral infection p...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://doi.org/10.1016/j.reaurg.2004.02.009</td>\n      <td>Re u et accept  le   f vrier      Les infectio...</td>\n      <td>et accept le vrier les infections virales resp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://doi.org/10.1016/0166-0934(92)90173-B</td>\n      <td>IEF  isoelectric focusing  NC  nitrocellulose ...</td>\n      <td>ief isoelectric nc tbs tris saline ph tbs milk...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "# # Preprocessing_type_1\n",
    "# medical_df['abstract'] = medical_df['abstract'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "# stopwords_list = stopwords.words('english')\n",
    "# punctuations = list(set(string.punctuation))\n",
    "\n",
    "# unwanted_list=punctuations+stopwords_list\n",
    "\n",
    "# def clean_text_initial(text):\n",
    "#     text = ' '.join([x.lower() for x in word_tokenize(text) if x.lower() not in unwanted_list and len(x)>1])\n",
    "#     text = ' '.join([x.lower() for x in word_tokenize(text) if nltk.pos_tag([x])[0][1].startswith(\"NN\") or nltk.pos_tag([x])[0][1].startswith(\"JJ\")])\n",
    "#     return text.strip()\n",
    "\n",
    "# medical_df[\"abstract_clean\"] = medical_df['abstract'].apply(lambda text:clean_text_initial(str(text)))\n",
    "# medical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "punctuations = list(set(string.punctuation))\n",
    "\n",
    "unwanted_list=punctuations+stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing part 2 - custom tokenizer\n",
    "def get_wordnet_pos(word):\n",
    "    '''tags parts of speech to tokens\n",
    "    Expects a string and outputs the string and \n",
    "    its part of speech'''\n",
    "    \n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    '''lemamtizes the tokens based on their part of speech'''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = lemmatizer.lemmatize(text, get_wordnet_pos(text))\n",
    "    return text\n",
    "\n",
    "def reflection_tokenizer(text):\n",
    "    '''expects a string an returns a list of lemmatized tokens \n",
    "    and removes the stop words. Tokens are lower cased and \n",
    "    non- alphanumeric characters as well as numbers removed. '''\n",
    "\n",
    "    text=re.sub(r'\\d+', '', text) #removes numbers\n",
    "    text = text.lower()\n",
    "    tokens = [word for word in word_tokenize(text)]\n",
    "    tokens = [word for word in tokens if len(word) >= 3]\n",
    "    #removes smaller than 3 character\n",
    "    tokens = [word_lemmatizer(w) for w in tokens]\n",
    "    tokens = [s for s in tokens if s not in unwanted_list]\n",
    "    text = ' '.join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           doi  \\\n",
       "0  http://doi.org/10.1016/j.vetmic.2006.11.026   \n",
       "1    http://doi.org/10.1016/j.jmii.2013.10.008   \n",
       "2    http://doi.org/10.1016/j.ajic.2017.01.009   \n",
       "3  http://doi.org/10.1016/j.reaurg.2004.02.009   \n",
       "4  http://doi.org/10.1016/0166-0934(92)90173-B   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Feline infectious peritonitis virus (FIPV) pos...   \n",
       "1  Objectives: This study was conducted to invest...   \n",
       "2  Of 7,772 laboratory-confirmed cases of respira...   \n",
       "3  Reçu et accepté le 7 février 2004 Les infectio...   \n",
       "4  IEF, isoelectric focusing; NC, nitrocellulose;...   \n",
       "\n",
       "                                      abstract_clean  \n",
       "0  feline infectious peritonitis virus fipv posit...  \n",
       "1  objective study conduct investigate correlatio...  \n",
       "2  laboratory-confirmed case respiratory viral in...  \n",
       "3  reçu accepté février le infection virales resp...  \n",
       "4  ief isoelectric focus nitrocellulose tb tris-b...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doi</th>\n      <th>abstract</th>\n      <th>abstract_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://doi.org/10.1016/j.vetmic.2006.11.026</td>\n      <td>Feline infectious peritonitis virus (FIPV) pos...</td>\n      <td>feline infectious peritonitis virus fipv posit...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://doi.org/10.1016/j.jmii.2013.10.008</td>\n      <td>Objectives: This study was conducted to invest...</td>\n      <td>objective study conduct investigate correlatio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://doi.org/10.1016/j.ajic.2017.01.009</td>\n      <td>Of 7,772 laboratory-confirmed cases of respira...</td>\n      <td>laboratory-confirmed case respiratory viral in...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://doi.org/10.1016/j.reaurg.2004.02.009</td>\n      <td>Reçu et accepté le 7 février 2004 Les infectio...</td>\n      <td>reçu accepté février le infection virales resp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://doi.org/10.1016/0166-0934(92)90173-B</td>\n      <td>IEF, isoelectric focusing; NC, nitrocellulose;...</td>\n      <td>ief isoelectric focus nitrocellulose tb tris-b...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "medical_df[\"abstract_clean\"] = medical_df['abstract'].apply(lambda text: reflection_tokenizer(str(text)))\n",
    "medical_df.head()"
   ]
  },
  {
   "source": [
    "# Get guided LDA topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus= medical_df[\"abstract_clean\"].tolist()\n",
    "vocab=list(set(word_tokenize(\" \".join(medical_df[\"abstract_clean\"]))))\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1),vocabulary=vocab)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "word2id=vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topic_list = [['expression', 'diagnostic', 'test', 'experiment'],\n",
    "['mouse', 'feline' , 'mammal', 'monkey', 'canine'],\n",
    "['bacterium', 'virus', 'microorganism', 'cell', 'microbial', 'pathogen'],\n",
    "['laboratory', 'hospital', 'pharmaceutical'],\n",
    "['protein', 'albumin', 'glycoprotein', 'antibody', 'rna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GuidedLDA(n_topics=5, n_iter=2000, random_state=7, refresh=20,alpha=0.01,eta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topics = {}\n",
    "for t_id, st in enumerate(seed_topic_list):\n",
    "    for word in st:\n",
    "        seed_topics[word2id[word]] = t_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:lda:n_documents: 10000\n",
      "INFO:lda:vocab_size: 68846\n",
      "INFO:lda:n_words: 1385257\n",
      "INFO:lda:n_topics: 5\n",
      "INFO:lda:n_iter: 2000\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -14118818\n",
      "INFO:lda:<20> log likelihood: -11763792\n",
      "INFO:lda:<40> log likelihood: -11562860\n",
      "INFO:lda:<60> log likelihood: -11501346\n",
      "INFO:lda:<80> log likelihood: -11475212\n",
      "INFO:lda:<100> log likelihood: -11460581\n",
      "INFO:lda:<120> log likelihood: -11454703\n",
      "INFO:lda:<140> log likelihood: -11446630\n",
      "INFO:lda:<160> log likelihood: -11442857\n",
      "INFO:lda:<180> log likelihood: -11438055\n",
      "INFO:lda:<200> log likelihood: -11434652\n",
      "INFO:lda:<220> log likelihood: -11432140\n",
      "INFO:lda:<240> log likelihood: -11430781\n",
      "INFO:lda:<260> log likelihood: -11427761\n",
      "INFO:lda:<280> log likelihood: -11427139\n",
      "INFO:lda:<300> log likelihood: -11427324\n",
      "INFO:lda:<320> log likelihood: -11426038\n",
      "INFO:lda:<340> log likelihood: -11425803\n",
      "INFO:lda:<360> log likelihood: -11424713\n",
      "INFO:lda:<380> log likelihood: -11423768\n",
      "INFO:lda:<400> log likelihood: -11422468\n",
      "INFO:lda:<420> log likelihood: -11424211\n",
      "INFO:lda:<440> log likelihood: -11423657\n",
      "INFO:lda:<460> log likelihood: -11422844\n",
      "INFO:lda:<480> log likelihood: -11425611\n",
      "INFO:lda:<500> log likelihood: -11424311\n",
      "INFO:lda:<520> log likelihood: -11424327\n",
      "INFO:lda:<540> log likelihood: -11424896\n",
      "INFO:lda:<560> log likelihood: -11423843\n",
      "INFO:lda:<580> log likelihood: -11422757\n",
      "INFO:lda:<600> log likelihood: -11421581\n",
      "INFO:lda:<620> log likelihood: -11421149\n",
      "INFO:lda:<640> log likelihood: -11420987\n",
      "INFO:lda:<660> log likelihood: -11422454\n",
      "INFO:lda:<680> log likelihood: -11422747\n",
      "INFO:lda:<700> log likelihood: -11423446\n",
      "INFO:lda:<720> log likelihood: -11422891\n",
      "INFO:lda:<740> log likelihood: -11421140\n",
      "INFO:lda:<760> log likelihood: -11422569\n",
      "INFO:lda:<780> log likelihood: -11422867\n",
      "INFO:lda:<800> log likelihood: -11422620\n",
      "INFO:lda:<820> log likelihood: -11421969\n",
      "INFO:lda:<840> log likelihood: -11422857\n",
      "INFO:lda:<860> log likelihood: -11421470\n",
      "INFO:lda:<880> log likelihood: -11422305\n",
      "INFO:lda:<900> log likelihood: -11420606\n",
      "INFO:lda:<920> log likelihood: -11422795\n",
      "INFO:lda:<940> log likelihood: -11420754\n",
      "INFO:lda:<960> log likelihood: -11420328\n",
      "INFO:lda:<980> log likelihood: -11422256\n",
      "INFO:lda:<1000> log likelihood: -11421158\n",
      "INFO:lda:<1020> log likelihood: -11421267\n",
      "INFO:lda:<1040> log likelihood: -11420009\n",
      "INFO:lda:<1060> log likelihood: -11421158\n",
      "INFO:lda:<1080> log likelihood: -11422433\n",
      "INFO:lda:<1100> log likelihood: -11423061\n",
      "INFO:lda:<1120> log likelihood: -11423623\n",
      "INFO:lda:<1140> log likelihood: -11422257\n",
      "INFO:lda:<1160> log likelihood: -11423220\n",
      "INFO:lda:<1180> log likelihood: -11421770\n",
      "INFO:lda:<1200> log likelihood: -11421790\n",
      "INFO:lda:<1220> log likelihood: -11423648\n",
      "INFO:lda:<1240> log likelihood: -11422172\n",
      "INFO:lda:<1260> log likelihood: -11422089\n",
      "INFO:lda:<1280> log likelihood: -11420881\n",
      "INFO:lda:<1300> log likelihood: -11421819\n",
      "INFO:lda:<1320> log likelihood: -11420758\n",
      "INFO:lda:<1340> log likelihood: -11421381\n",
      "INFO:lda:<1360> log likelihood: -11422927\n",
      "INFO:lda:<1380> log likelihood: -11420989\n",
      "INFO:lda:<1400> log likelihood: -11422273\n",
      "INFO:lda:<1420> log likelihood: -11423094\n",
      "INFO:lda:<1440> log likelihood: -11421737\n",
      "INFO:lda:<1460> log likelihood: -11422490\n",
      "INFO:lda:<1480> log likelihood: -11422254\n",
      "INFO:lda:<1500> log likelihood: -11422231\n",
      "INFO:lda:<1520> log likelihood: -11421492\n",
      "INFO:lda:<1540> log likelihood: -11422010\n",
      "INFO:lda:<1560> log likelihood: -11422329\n",
      "INFO:lda:<1580> log likelihood: -11422869\n",
      "INFO:lda:<1600> log likelihood: -11421151\n",
      "INFO:lda:<1620> log likelihood: -11420455\n",
      "INFO:lda:<1640> log likelihood: -11421979\n",
      "INFO:lda:<1660> log likelihood: -11423373\n",
      "INFO:lda:<1680> log likelihood: -11422944\n",
      "INFO:lda:<1700> log likelihood: -11423894\n",
      "INFO:lda:<1720> log likelihood: -11422935\n",
      "INFO:lda:<1740> log likelihood: -11422078\n",
      "INFO:lda:<1760> log likelihood: -11424528\n",
      "INFO:lda:<1780> log likelihood: -11422817\n",
      "INFO:lda:<1800> log likelihood: -11423572\n",
      "INFO:lda:<1820> log likelihood: -11420719\n",
      "INFO:lda:<1840> log likelihood: -11421925\n",
      "INFO:lda:<1860> log likelihood: -11422589\n",
      "INFO:lda:<1880> log likelihood: -11423193\n",
      "INFO:lda:<1900> log likelihood: -11422138\n",
      "INFO:lda:<1920> log likelihood: -11422819\n",
      "INFO:lda:<1940> log likelihood: -11422851\n",
      "INFO:lda:<1960> log likelihood: -11421528\n",
      "INFO:lda:<1980> log likelihood: -11423468\n",
      "INFO:lda:<1999> log likelihood: -11423604\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.GuidedLDA at 0x7fd8b35c83d0>"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "model.fit(X, seed_topics=seed_topics, seed_confidence=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic 0: virus sample use strain sequence assay pcr study detection detect\nTopic 1: disease health use model study data outbreak system public method\nTopic 2: cell infection response virus mouse immune expression vaccine study induced\nTopic 3: patient respiratory infection virus study case child clinical influenza group\nTopic 4: protein virus cell rna viral cov sars host human use\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "topic_word = model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num_name = {\"Topic 0\":\"analysis\",\n",
    "                  \"Topic 1\":\"animals\",\n",
    "                  \"Topic 2\":\"microorganism\",\n",
    "                  \"Topic 3\":\"place\",\n",
    "                  \"Topic 4\":\"cellular component\"}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_topics(model_glda,X,num_topics,dataframe,col_name):\n",
    "    \"\"\"\n",
    "    A function which creates dataframe with documents, their dominant topic, along with their probabilities\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    model_glda - Guided LDA trained model\n",
    "    X - Document term frequency table\n",
    "    num_topics - Number of topics the model was trained for\n",
    "    dataframe - Dataframe consisting of cleaned text column\n",
    "    col_name - Column name in dataframe holding cleaned text\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    A dataframe with document number, topic, probability of topic\n",
    "    \"\"\"\n",
    "    df_doc_top = pd.DataFrame()\n",
    "    final_list = []\n",
    "    for index in range(len(dataframe[col_name])):\n",
    "        word_id_dict = dict((x,y) for x,y in zip([x for x in range(num_topics)],np.round(model.transform(X[index])*100,1).tolist()[0]))\n",
    "        word_score_list = []\n",
    "        for index in range(num_topics):\n",
    "            try:\n",
    "                value = word_id_dict[index]\n",
    "            except:\n",
    "                value = 0\n",
    "            word_score_list.append(value)\n",
    "        final_list.append(word_score_list)\n",
    "\n",
    "    df_doc_top = pd.DataFrame(final_list)\n",
    "    df_doc_top.columns = ['Topic ' + str(i) for i in range(num_topics)]\n",
    "    df_doc_top.index = ['Document ' + str(i) for i in range(len(dataframe[col_name]))]\n",
    "\n",
    "    df_doc_top[\"Dominant_Topic\"] = df_doc_top.idxmax(axis=1).tolist()\n",
    "    df_doc_top[\"Topic_Probability\"] = df_doc_top.max(axis=1).tolist()\n",
    "    document_df = df_doc_top.reset_index().rename(columns={\"index\":\"Document\"})[[\"Document\",\"Dominant_Topic\",\"Topic_Probability\"]]\n",
    "\n",
    "    return document_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "a:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n",
      "WARNING:lda:all zero column in document-term matrix found\n"
     ]
    }
   ],
   "source": [
    "document_df=get_doc_topics(model,X,5,medical_df,\"abstract_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Document Dominant_Topic  Topic_Probability\n",
       "0  Document 0        Topic 4               53.3\n",
       "1  Document 1        Topic 2               55.1\n",
       "2  Document 2        Topic 2               99.9\n",
       "3  Document 3        Topic 2               92.6\n",
       "4  Document 4        Topic 0               59.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Document</th>\n      <th>Dominant_Topic</th>\n      <th>Topic_Probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Document 0</td>\n      <td>Topic 4</td>\n      <td>53.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Document 1</td>\n      <td>Topic 2</td>\n      <td>55.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Document 2</td>\n      <td>Topic 2</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Document 3</td>\n      <td>Topic 2</td>\n      <td>92.6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Document 4</td>\n      <td>Topic 0</td>\n      <td>59.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}