{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install extra-dependencies\n",
    "!pip -q install git+https://www.github.com/keras-team/keras-contrib.git sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\n",
      "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from keras==2.2.4) (1.18.0)\n",
      "Requirement already satisfied: pyyaml in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from keras==2.2.4) (5.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: h5py in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    BATCH_SIZE = 512  # Number of examples used in each iteration\n",
    "    EPOCHS = 5  # Number of passes through entire dataset\n",
    "    MAX_LEN = 75  # Max length of review (in words)\n",
    "    EMBEDDING = 40  # Dimension of word embedding vector\n",
    "\n",
    "    \n",
    "# Hyperparams for CPU training\n",
    "else:\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 5\n",
    "    MAX_LEN = 75\n",
    "    EMBEDDING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:  47959\n",
      "Number of words in the dataset:  35178\n",
      "Tags: ['I-eve', 'I-nat', 'O', 'B-gpe', 'I-gpe', 'I-per', 'I-art', 'B-tim', 'B-nat', 'B-geo', 'B-org', 'B-art', 'B-per', 'I-org', 'I-geo', 'I-tim', 'B-eve']\n",
      "Number of Labels:  17\n",
      "What the dataset looks like:\n",
      "    Sentence #           Word  POS    Tag\n",
      "0  Sentence: 1      Thousands  NNS      O\n",
      "1  Sentence: 1             of   IN      O\n",
      "2  Sentence: 1  demonstrators  NNS      O\n",
      "3  Sentence: 1           have  VBP      O\n",
      "4  Sentence: 1        marched  VBN      O\n",
      "5  Sentence: 1        through   IN      O\n",
      "6  Sentence: 1         London  NNP  B-geo\n",
      "7  Sentence: 1             to   TO      O\n",
      "8  Sentence: 1        protest   VB      O\n",
      "9  Sentence: 1            the   DT      O\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/patsnap/Desktop/Neo4J_and_other_codes/Topic_modelling/ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "\n",
    "print(\"Number of sentences: \", len(data.groupby(['Sentence #'])))\n",
    "\n",
    "words = list(set(data[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "print(\"Number of words in the dataset: \", n_words)\n",
    "\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "print(\"Tags:\", tags)\n",
    "n_tags = len(tags)\n",
    "print(\"Number of Labels: \", n_tags)\n",
    "\n",
    "print(\"What the dataset looks like:\")\n",
    "# Show the first 10 rows\n",
    "print(data.head(n=10))\n",
    "print(n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what a sentence looks like:\n",
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "class SentenceGetter(object):\n",
    "    \"\"\"Class to Get the sentence in this format:\n",
    "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_1, Tag_1)]\"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Args:\n",
    "            data is the pandas.DataFrame which contains the above dataset\"\"\"\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        \"\"\"Return one sentence\"\"\"\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "print('This is what a sentence looks like:')\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get all the sentences\n",
    "sentences = getter.sentences\n",
    "\n",
    "# Plot sentence by lenght\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.title('Token per sentence')\n",
    "plt.xlabel('Len (number of token)')\n",
    "plt.ylabel('# samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Before feeding the data into the model, we have to preprocess the text.\n",
    "We will use the word2idx dictionary to convert each word to a corresponding integer ID and the tag2idx to do the same for the labels. Representing words as integers saves a lot of memory!\n",
    "In order to feed the text into our Bi-LSTM-CRF, all texts should be the same length. We ensure this using the sequence.pad_sequences() method and MAX_LEN variable. All texts longer than MAX_LEN are truncated and shorter texts are padded to get them to the same length.\n",
    "The Tokens per sentence plot (see above) is useful for setting the MAX_LEN training hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word Obama is identified by the index: 33351\n",
      "The labels B-geo(which defines Geopraphical Enitities) is identified by the index: 10\n",
      "Raw Sample:  Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "Raw Label:  O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
      "After processing, sample: [14737 15580 24597  9874  1980  2478 25286 14005 30521 12223  9905 33030\n",
      " 23173 28481  9793 12223 16036 15580  5178 27545 21152 34455  6008 11465\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "After processing, labels: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary Key:word -> Value:token_index\n",
    "# The first 2 entries are reserved for PAD and UNK\n",
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1 # Unknown words\n",
    "word2idx[\"PAD\"] = 0 # Padding\n",
    "\n",
    "# Vocabulary Key:token_index -> Value:word\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "# Vocabulary Key:Label/Tag -> Value:tag_index\n",
    "# The first entry is reserved for PAD\n",
    "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "# Vocabulary Key:tag_index -> Value:Label/Tag\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "print(\"The word Obama is identified by the index: {}\".format(word2idx[\"Obama\"]))\n",
    "print(\"The labels B-geo(which defines Geopraphical Enitities) is identified by the index: {}\".format(tag2idx[\"B-geo\"]))\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Convert each sentence from list of Token to list of word_index\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "# Padding each sentence to have the same lenght\n",
    "X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
    "\n",
    "# Convert Tag/Label to tag_index\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "# Padding each sentence to have the same lenght\n",
    "y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# One-Hot encode\n",
    "y = [to_categorical(i, num_classes=n_tags+1) for i in y]  # n_tags+1(PAD)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "X_tr.shape, X_te.shape, np.array(y_tr).shape, np.array(y_te).shape\n",
    "\n",
    "print('Raw Sample: ', ' '.join([w[0] for w in sentences[0]]))\n",
    "print('Raw Label: ', ' '.join([w[2] for w in sentences[0]]))\n",
    "print('After processing, sample:', X[0])\n",
    "print('After processing, labels:', y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM-CRF Models for Sequence Tagging.\n",
    "https://arxiv.org/pdf/1508.01991v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_20 (Embedding)     (None, 75, 20)            703600    \n",
      "_________________________________________________________________\n",
      "bidirectional_19 (Bidirectio (None, 75, 100)           28400     \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_16 (CRF)                 (None, 75, 18)            1278      \n",
      "=================================================================\n",
      "Total params: 738,328\n",
      "Trainable params: 738,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#don't put mask_zero = True causes problems\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "# Model definition\n",
    "input = Input(shape=(MAX_LEN,))\n",
    "model = Embedding(input_dim=len(words)+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)\n",
    "                  input_length=MAX_LEN, mask_zero=False)(input)  # default: 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/patsnap/anaconda2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 38846 samples, validate on 4317 samples\n",
      "Epoch 1/5\n",
      " - 119s - loss: 0.1263 - crf_viterbi_accuracy: 0.9644 - val_loss: 0.0313 - val_crf_viterbi_accuracy: 0.9852\n",
      "Epoch 2/5\n",
      " - 111s - loss: 0.0140 - crf_viterbi_accuracy: 0.9876 - val_loss: 7.3558e-04 - val_crf_viterbi_accuracy: 0.9888\n",
      "Epoch 3/5\n",
      " - 103s - loss: -1.1778e-02 - crf_viterbi_accuracy: 0.9902 - val_loss: -1.9348e-02 - val_crf_viterbi_accuracy: 0.9898\n",
      "Epoch 4/5\n",
      " - 103s - loss: -3.1495e-02 - crf_viterbi_accuracy: 0.9912 - val_loss: -3.6928e-02 - val_crf_viterbi_accuracy: 0.9901\n",
      "Epoch 5/5\n",
      " - 103s - loss: -4.9408e-02 - crf_viterbi_accuracy: 0.9919 - val_loss: -5.3870e-02 - val_crf_viterbi_accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "pred_cat = model.predict(X_te)\n",
    "pred = np.argmax(pred_cat, axis=-1)\n",
    "y_te_true = np.argmax(y_te, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patsnap/anaconda2/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        29\n",
      "       B-eve       0.67      0.22      0.33        45\n",
      "       B-geo       0.85      0.89      0.87      3809\n",
      "       B-gpe       0.97      0.92      0.94      1534\n",
      "       B-nat       0.00      0.00      0.00        33\n",
      "       B-org       0.76      0.70      0.73      2030\n",
      "       B-per       0.84      0.80      0.82      1702\n",
      "       B-tim       0.91      0.87      0.89      1951\n",
      "       I-art       0.00      0.00      0.00        24\n",
      "       I-eve       0.17      0.02      0.04        43\n",
      "       I-geo       0.76      0.82      0.79       766\n",
      "       I-gpe       1.00      0.44      0.62        18\n",
      "       I-nat       0.00      0.00      0.00         9\n",
      "       I-org       0.76      0.75      0.76      1673\n",
      "       I-per       0.84      0.87      0.85      1702\n",
      "       I-tim       0.80      0.73      0.76       618\n",
      "           O       0.99      0.99      0.99     89350\n",
      "         PAD       1.00      1.00      1.00    254364\n",
      "\n",
      "    accuracy                           0.99    359700\n",
      "   macro avg       0.63      0.56      0.58    359700\n",
      "weighted avg       0.99      0.99      0.99    359700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "# Convert the index to tag\n",
    "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
    "y_te_true_tag = [[idx2tag[i] for i in row] for row in y_te_true] \n",
    "\n",
    "report = flat_classification_report(y_pred=pred_tag, y_true=y_te_true_tag)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#evaluate on some sample of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number 1277 of 4796 (Test Set)\n",
      "Word           ||True ||Pred\n",
      "==============================\n",
      "The            : O     O\n",
      "pro-Western    : B-org O\n",
      "Mr.            : B-per B-per\n",
      "Tadic          : B-org I-per\n",
      "was            : O     O\n",
      "not            : O     O\n",
      "hurt           : O     O\n",
      ".              : O     O\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0,X_te.shape[0]) # choose a random number between 0 and len(X_te)\n",
    "p = model.predict(np.array([X_te[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_te[i], -1)\n",
    "\n",
    "print(\"Sample number {} of {} (Test Set)\".format(i, X_te.shape[0]))\n",
    "# Visualization\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_te[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-2], idx2tag[t], idx2tag[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5333aa6c444a454ea88745c8d35b841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='', description='sentence', placeholder='Type your sentence here'), Butto…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Custom Tokenizer\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "    \n",
    "def get_prediction(sentence):\n",
    "    test_sentence = tokenize(sentence) # Tokenization\n",
    "    # Preprocessing\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=word2idx[\"PAD\"], maxlen=MAX_LEN)\n",
    "    # Evaluation\n",
    "    p = model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    # Visualization\n",
    "    print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "    print(30 * \"=\")\n",
    "    for w, pred in zip(test_sentence, p[0]):\n",
    "        print(\"{:15}: {:5}\".format(w, idx2tag[pred]))\n",
    "\n",
    "interact_manual(get_prediction, sentence=widgets.Textarea(placeholder='Type your sentence here'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Saving Vocab\n",
    "# with open('models/word_to_index.pickle', 'wb') as handle:\n",
    "#     pickle.dump(word2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    " \n",
    "# # Saving Vocab\n",
    "# with open('models/tag_to_index.pickle', 'wb') as handle:\n",
    "#     pickle.dump(tag2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# # Saving Model Weight\n",
    "# model.save_weights('models/lstm_crf_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
