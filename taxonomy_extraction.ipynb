{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 8.3 MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
      "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61084 sha256=5acdbe29ef215b3ab75d7353ae1245b23eb873e093944cfac86706ca229544f4\n",
      "  Stored in directory: /Users/sdeshpande/Library/Caches/pip/wheels/b1/1a/8f/a4c34be976825a2f7948d0fa40907598d69834f8ab5889de11\n",
      "Successfully built PyPDF2\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-1.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/sdeshpande/Desktop/text_analysis_scripts/sample_text.pdf','rb') as pdf_file, open('/Users/sdeshpande/Desktop/text_analysis_scripts/sample.txt', 'w') as text_file:\n",
    "    read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "    number_of_pages = read_pdf.getNumPages()\n",
    "    for page_number in range(number_of_pages):   \n",
    "        page = read_pdf.getPage(page_number)\n",
    "        page_content = page.extractText()\n",
    "        text_file.write(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/sdeshpande/Desktop/text_analysis_scripts/sample.txt', 'r', encoding=\"latin-1\") as f:\n",
    "    read_output = f.readlines()\n",
    "read_output = '\\n'.join(read_output).strip().replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;.]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "SHORTWORD = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "\n",
    "stop_words_lst = ['cell','spectral','data','double','bond','barrier','soluble', 'cells', 'performed using']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = str(text).lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing.\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b','',str(text)) # remove single letter words\n",
    "    text = re.sub('\\d+','',text) # remove digits\n",
    "    text = SHORTWORD.sub('',text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    for w in stop_words_lst:\n",
    "        pattern = r'\\b'+w+r'\\b'\n",
    "        text = re.sub(pattern, '', str(text))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_o = clean_text(read_output)\n",
    "text_tokens = word_tokenize(pdf_o)\n",
    "\n",
    "pdf_i=[pdf_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "                                   term  rank\n",
      "5583                  pluripotent stem    20\n",
      "1365                 cluster formation    11\n",
      "2792                   fisher scientic    10\n",
      "2506              ermo fisher scientic    10\n",
      "2505                       ermo fisher    10\n",
      "1154             cellcluster formation     7\n",
      "4626                    medium changed     7\n",
      "5090                       normal hdfs     7\n",
      "2550                        every days     6\n",
      "290                        alexa fluor     6\n",
      "4629                 medium containing     6\n",
      "3928          induced pluripotent stem     5\n",
      "3927               induced pluripotent     5\n",
      "4628              medium changed fresh     5\n",
      "6396                     rics cultured     5\n",
      "4965                         natl acad     5\n",
      "6325                ribosomes isolated     5\n",
      "2812                  fluor phalloidin     5\n",
      "4635                      medium every     5\n",
      "6263            ribosome incorporation     5\n",
      "98                  acidophilus lysate     5\n",
      "292             alexa fluor phalloidin     5\n",
      "5735                         proc natl     5\n",
      "1406                  clusters induced     5\n",
      "4851                  molecular probes     5\n",
      "5736                    proc natl acad     5\n",
      "1253                     changed fresh     5\n",
      "7530             transcription factors     5\n",
      "3066                   gene expression     5\n",
      "1203       cellular transdierentiation     5\n",
      "4373                     listed tables     4\n",
      "2403                    embryonic stem     4\n",
      "8117                        well plate     4\n",
      "6414                 rics dierentiated     4\n",
      "2606                    expressed rics     4\n",
      "416                      analysis rics     4\n",
      "82                       acid bacteria     4\n",
      "1765                  creative commons     4\n",
      "273               agilent technologies     4\n",
      "4704                  mesenchymal stem     4\n",
      "2177         dierentiation ermo fisher     4\n",
      "2176                dierentiation ermo     4\n",
      "6943              stained hoechst blue     4\n",
      "6942                   stained hoechst     4\n",
      "3569                   human broblasts     4\n",
      "4209                       lactic acid     4\n",
      "3512                      hoechst blue     4\n",
      "2491  epithelialmesenchymal transition     4\n",
      "4198               kumamoto university     4\n",
      "2648               expression patterns     4\n"
     ]
    }
   ],
   "source": [
    "# Getting bigrams\n",
    "vectorizer = CountVectorizer(ngram_range =(2, 3))\n",
    "X1 = vectorizer.fit_transform(pdf_i)\n",
    "features = (vectorizer.get_feature_names())\n",
    "\n",
    "X2 = vectorizer.fit_transform(pdf_i)\n",
    "scores = (X2.toarray())\n",
    "\n",
    "sums = X2.sum(axis = 0)\n",
    "data1 = []\n",
    "for col, term in enumerate(features):\n",
    "    data1.append( (term, sums[0, col] ))\n",
    "ranking = pd.DataFrame(data1, columns = ['term', 'rank'])\n",
    "words = (ranking.sort_values('rank', ascending = False))\n",
    "print (\"\\n\\nWords : \\n\", words.head(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
